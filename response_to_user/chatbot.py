import random
import json
import pickle
import numpy as np
import nltk
nltk.download('punkt')
nltk.download('wordnet')
from nltk import WordNetLemmatizer

from tensorflow.keras.models import load_model

lemmatizer = WordNetLemmatizer()
intents = json.loads(open('./response_to_user/intents.json').read())

words = pickle.load(open('./response_to_user/words.pkl', 'rb'))
classes = pickle.load(open('./response_to_user/classes.pkl', 'rb'))
model = load_model('./response_to_user/chatbot_model.h5')


def clean_up_sentence(sentence):
  sentence_words = nltk.word_tokenize(sentence)
  sentence_words = [lemmatizer.lemmatize(word) for word in sentence_words]
  return sentence_words


def bag_of_words(sentence):
  sentence_words = clean_up_sentence(sentence)
  bag = [0] * len(words)
  for w in sentence_words:
    for i, word in enumerate(words):
      if word == w:
        bag[i] = 1
  return np.array(bag)


def predict_class(sentence):
  bow = bag_of_words(sentence)
  res = model.predict(np.array([bow]), verbose=0)[0]
  ERROR_THRESHOLD = 0.25
  results = [[i, r] for i, r in enumerate(res) if r > ERROR_THRESHOLD]

  results.sort(key=lambda x: x[1], reverse=True)
  return_list = []
  for r in results:
    return_list.append({'intent': classes[r[0]], 'probalility': str(r[1])})
  return return_list


def get_response(message):
  if message.lower() in message_dict:
    return message_dict[message.lower()]
  else:
    intents_list = predict_class(message.lower())
    tag = intents_list[0]['intent']
    list_of_intents = intents['intents']
    for i in list_of_intents:
      if i['tag'] == tag:
        result = random.choice(i['responses'])
    return result


print('________GOOOO___________')

message_dict = {
    '–º–∞—Ç–µ–º–∞—Ç–∏–∫–∞':
    '–û—Å—å, –ø–æ–≤—á–∏ —Ç—Ä–æ—à–∫–∏ - https://waytomathematics.blogspot.com/p/zno.html',
    '—Å–µ–∫—Ä–µ—Ç':
    '–•–æ—á–µ—à –¥—ñ–∑–Ω–∞—Ç–∏—Å—å —Ç–∞—î–º–Ω–∏—Ü—é –≤—Å—ñ—Ö —á–∞—Å—ñ–≤ —ñ –Ω–∞—Ä–æ–¥—ñ–≤? –†–æ–∑–≥–∞–¥–∞–π –Ω–∞—Å—Ç—É–ø–Ω—É –∑–∞–≥–∞–¥–∫—É - "–ì—ñ—Ä—à–µ —Ä–æ–±–∏—Ç–∏ –∞–Ω–æ–º–∞–ª—ñ—é. –í—ñ—Ä–∏—Ç–∏. –ë—ñ–ª—å—à–µ —ñ–Ω—à—ñ —Å–Ω—ñ–∂–∏—Ç–∏–º–º—É—Ç—å –µ–ø–æ–∫—Å–∏–¥–Ω–æ—é –∫—Ä–∞—Å–æ—é —Ä—ñ—á–∫–∏"',
    '–≥—Ä–∞ –≤ –±—ñ—Å–µ—Ä':
    '–ê —Ç–∏ –∫—Ä—É—Ç–∏–π, –æ—Å—å –ø–æ–¥–∞—Ä—É–Ω–æ–∫ - https://www.youtube.com/watch?v=PcawW1eO-KY',
    '–≤–æ–Ω–∞ –Ω–æ—Å–∏–ª–∞ –∫–≤—ñ—Ç–∏ —É –≤–æ–ª–æ—Å—Å—ñ': '–Ü –Ω–∏–º–∏ –≥—Ä–∞–≤—Å—è –≤—ñ —Ç–∞ —â–µ –π –≤—ñ—Ç–µ—Ä',
    '–∑–¥–∞–≤–∞–ª–æ—Å—è –¥–∞–≤–Ω–æ –≤–∂–µ –¥–æ—Ä–æ—Å–ª—ñ': '–ê–ª–µ –∫–æ—Ö–∞–ª–∏ —â–∏—Ä–æ, –º–æ–≤ –¥—ñ—Ç–∏',
    '1984': '–°—Ç–∞—Ä—à–∏–π –±—Ä–∞—Ç —Å—Ç–µ–∂–∏—Ç—å –∑–∞ —Ç–æ–±–æ—é',
    '–∫–ª—é—á': '–ù–µ–∑–∞–±–∞—Ä–æ–º —â–æ—Å—å –ø—Ä–∏–¥—É–º–∞—é',
    '—è–∫–µ –ø–æ—Å–∏–ª–∞–Ω–Ω—è?': '–Ø–∫ —è–∫–µ, –∑ YouTube, –æ—Å—å: https://www.youtube.com',
    '—è–∫–µ –ø–æ—Å–∏–ª–∞–Ω–Ω—è': '–Ø–∫ —è–∫–µ, –∑ YouTube, –æ—Å—å: https://www.youtube.com',
    '–¥–æ–±—Ä': '–µ \n–ë—É–∫–≤–∏ —à–∫–æ–¥–∞?',
    '–Ω–∞ –¥–æ–±—Ä–∞–Ω—ñ—á': '–ù–∞ –¥–æ–±—Ä–∞–Ω—ñ—á üñ§',
    '—Å–ª–∞–≤–∞ —É–∫—Ä–∞—ó–Ω—ñ': '–ì–µ—Ä–æ—è–º –°–ª–∞–≤–∞ üá∫üá¶'
}
